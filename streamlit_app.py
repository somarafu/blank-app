import streamlit as st
import pandas as pd
import numpy as np
from sklearn.cluster import KMeans # í´ëŸ¬ìŠ¤í„°ë§ì„ ìœ„í•´
import datetime

# --- 1. ì•± ì„¤ì • ---
st.set_page_config(
    page_title="í•œêµ­ ì‹œìœ„ ë°ì´í„° ëŒ€ì‹œë³´ë“œ",
    page_icon="ğŸ‡°ğŸ‡·",
    layout="wide"
)

# --- 2. (ì¤‘ìš”) ë°ì´í„° ë¡œë”© ---
# @st.cache_dataë¥¼ ì‚¬ìš©í•˜ë©´ ë°ì´í„° ë¡œë”©ì„ ìºì‹œí•˜ì—¬ ì•± ì†ë„ë¥¼ ë†’ì…ë‹ˆë‹¤.
@st.cache_data
def load_data(nrows):
    """
    ì´ í•¨ìˆ˜ëŠ” ì‹¤ì œ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ëŠ” ë¶€ë¶„ì…ë‹ˆë‹¤.
    ì§€ê¸ˆì€ 10,000ê°œì˜ ê°€ìƒ ì‹œìœ„ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    *** ì‚¬ìš©ìê°€ ì‹¤ì œ ë°ì´í„°ë¥¼ ê°€ì§€ê³  ìˆë‹¤ë©´ ì´ í•¨ìˆ˜ ë‚´ë¶€ë¥¼ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤. ***
    
    ì˜ˆ:
    try:
        data = pd.read_csv('your_protest_data.csv')
        # 'date' ì»¬ëŸ¼ì´ ë¬¸ìì—´ì´ë¼ë©´ datetimeìœ¼ë¡œ ë³€í™˜í•´ì•¼ í•©ë‹ˆë‹¤.
        data['date'] = pd.to_datetime(data['date_column_name'])
        # 'lat', 'lon' ì»¬ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.
        
    except FileNotFoundError:
        st.error("ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 'your_protest_data.csv'ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")
        return pd.DataFrame()
        
    return data
    """
    
    # --- ê°€ìƒ ë°ì´í„° ìƒì„± ì‹œì‘ (ì‹¤ì œ ë°ì´í„°ë¡œ ì´ ë¶€ë¶„ì„ êµì²´í•˜ì„¸ìš”) ---
    N_ROWS = nrows
    DATE_COLUMN = 'date'
    
    # í•œêµ­ì˜ ì£¼ìš” ë„ì‹œ ì¤‘ì‹¬ ì¢Œí‘œ (ì„œìš¸, ë¶€ì‚°, ê´‘ì£¼)
    cities = {
        'Seoul': (37.5665, 126.9780),
        'Busan': (35.1796, 129.0756),
        'Gwangju': (35.1595, 126.8526)
    }
    
    data = []
    np.random.seed(42)
    
    for _ in range(N_ROWS):
        city_name = np.random.choice(list(cities.keys()), p=[0.6, 0.2, 0.2]) # ì„œìš¸ 60%, ë¶€ì‚°/ê´‘ì£¼ 20%
        lat, lon = cities[city_name]
        
        # ì¤‘ì‹¬ ì¢Œí‘œ ê·¼ì²˜ì— ë¬´ì‘ìœ„ë¡œ ì  ìƒì„±
        lat_offset = np.random.normal(0, 0.03) # ì•½ 3.3km ë°˜ê²½
        lon_offset = np.random.normal(0, 0.03) # ì•½ 3.3km ë°˜ê²½
        
        data.append({
            DATE_COLUMN: datetime.datetime(
                2024, 
                np.random.randint(1, 13), 
                np.random.randint(1, 28), 
                np.random.randint(0, 24), 
                np.random.randint(0, 60)
            ),
            'lat': lat + lat_offset,
            'lon': lon + lon_offset,
            'protest_type': np.random.choice(['ë…¸ë™', 'ì‹œë¯¼', 'í™˜ê²½', 'ê°œì¸']),
            'scale': np.random.choice(['ì†Œê·œëª¨', 'ì¤‘ê·œëª¨', 'ëŒ€ê·œëª¨'], p=[0.5, 0.3, 0.2])
        })
    
    data = pd.DataFrame(data)
    data['hour'] = data[DATE_COLUMN].dt.hour
    # --- ê°€ìƒ ë°ì´í„° ìƒì„± ì¢…ë£Œ ---
    
    return data

# í´ëŸ¬ìŠ¤í„°ë§ ì‹œê°í™”ë¥¼ ìœ„í•œ ìƒ‰ìƒ (10ê°œ)
CLUSTER_COLORS = ['#FF0000', '#0000FF', '#00FF00', '#FFFF00', '#00FFFF', 
                  '#FF00FF', '#FFA500', '#800080', '#008000', '#800000']


# --- 3. ì‚¬ì´ë“œë°” (í•„í„°) ---
st.sidebar.header("ë°ì´í„° í•„í„°")

# 3-1. ì‹œê°„ ì„ íƒ ìŠ¬ë¼ì´ë”
hour_to_filter = st.sidebar.slider(
    'ì‹œê°„ ì„ íƒ:',
    min_value=0,
    max_value=23,
    value=17, # ê¸°ë³¸ê°’ 17ì‹œ
    step=1
)

# 3-2. ì‹œìœ„ ìœ í˜• í•„í„° (Multiselect)
all_types = ['ë…¸ë™', 'ì‹œë¯¼', 'í™˜ê²½', 'ê°œì¸']
types_to_filter = st.sidebar.multiselect(
    'ì‹œìœ„ ìœ í˜• ì„ íƒ:',
    options=all_types,
    default=all_types # ê¸°ë³¸ìœ¼ë¡œ ëª¨ë‘ ì„ íƒ
)

# 3-3. ì‹œìœ„ ê·œëª¨ í•„í„° (Multiselect)
all_scales = ['ì†Œê·œëª¨', 'ì¤‘ê·œëª¨', 'ëŒ€ê·œëª¨']
scales_to_filter = st.sidebar.multiselect(
    'ì‹œìœ„ ê·œëª¨ ì„ íƒ:',
    options=all_scales,
    default=all_scales # ê¸°ë³¸ìœ¼ë¡œ ëª¨ë‘ ì„ íƒ
)

# 3-4. í´ëŸ¬ìŠ¤í„° ê°œìˆ˜(K) ìŠ¬ë¼ì´ë” (ë‰´ìš• ì˜ˆì œì™€ ë™ì¼)
k_clusters = st.sidebar.slider(
    'í´ëŸ¬ìŠ¤í„° ê°œìˆ˜ (K):',
    min_value=1,
    max_value=10,
    value=1, # ê¸°ë³¸ê°’ 1 (í´ëŸ¬ìŠ¤í„°ë§ ì—†ìŒ)
    help='K=1ì€ í´ëŸ¬ìŠ¤í„°ë§ì„ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. 2 ì´ìƒì„ ì„ íƒí•˜ë©´ K-Means í´ëŸ¬ìŠ¤í„°ë§ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.'
)


# --- 4. ë°ì´í„° ë¡œë”© ë° í•„í„°ë§ ---
# ë°ì´í„° ë¡œë“œ
data = load_data(10000)

# í•„í„° ì ìš©
filtered_data = data[
    (data['hour'] == hour_to_filter) &
    (data['protest_type'].isin(types_to_filter)) &
    (data['scale'].isin(scales_to_filter))
]

# --- 5. ë©”ì¸ íŒ¨ë„ (ì‹œê°í™”) ---
st.title("ğŸ‡°ğŸ‡· í•œêµ­ ì‹œìœ„ ë°ì´í„° ì‹¤ì‹œê°„ ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
st.markdown("ì´ ëŒ€ì‹œë³´ë“œëŠ” ê°€ìƒì˜ ì‹œìœ„ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¹ì • ì‹œê°„ëŒ€ì™€ ì¡°ê±´ì— ë§ëŠ” ì‹œìœ„ ë°œìƒ ìœ„ì¹˜ë¥¼ ì§€ë„ì— í‘œì‹œí•©ë‹ˆë‹¤.")

# 5-1. ë§µ ì‹œê°í™” (í´ëŸ¬ìŠ¤í„°ë§ í¬í•¨)
subheader_text = f"ì‹œê°„: {hour_to_filter}:00, ì„ íƒëœ ì‹œìœ„ ê±´ìˆ˜: {len(filtered_data)}ê±´"
if k_clusters > 1:
    subheader_text += f" (K={k_clusters} í´ëŸ¬ìŠ¤í„°ë§ ì ìš©)"
st.subheader(subheader_text)


if not filtered_data.empty:
    if k_clusters > 1:
        # K=2 ì´ìƒì´ë©´ K-Means í´ëŸ¬ìŠ¤í„°ë§ ì‹¤í–‰
        with st.spinner('ìœ„ì¹˜ í´ëŸ¬ìŠ¤í„°ë§ ì¤‘...'):
            kmeans = KMeans(n_clusters=k_clusters, n_init=10, random_state=42)
            filtered_data['cluster'] = kmeans.fit_predict(filtered_data[['lat', 'lon']])
            
            # í´ëŸ¬ìŠ¤í„° ë²ˆí˜¸ì— ë”°ë¼ ìƒ‰ìƒ ë§¤í•‘
            filtered_data['color'] = filtered_data['cluster'].apply(
                lambda x: CLUSTER_COLORS[x % len(CLUSTER_COLORS)]
            )
            
            # 'color' ì»¬ëŸ¼ì„ ì‚¬ìš©í•˜ì—¬ ì§€ë„ì— ìƒ‰ìƒ í‘œì‹œ
            st.map(filtered_data, color='color')
            
    else:
        # K=1ì´ë©´ (ê¸°ë³¸ê°’) í´ëŸ¬ìŠ¤í„°ë§ ì—†ì´ í‘œì‹œ
        st.map(filtered_data)
        
else:
    st.warning("ì´ ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

# 5-2. ì‹œê°„ëŒ€ë³„ í†µê³„ (ë§‰ëŒ€ ì°¨íŠ¸)
st.subheader("ì „ì²´ ì‹œê°„ëŒ€ë³„ ì‹œìœ„ ë°œìƒ ê±´ìˆ˜")
# ì›ë³¸ 'data'ë¥¼ ì‚¬ìš©í•´ ì „ì²´ ì‹œê°„ëŒ€ë³„ íˆìŠ¤í† ê·¸ë¨ ìƒì„±
hist_values = np.histogram(data['hour'], bins=24, range=(0, 24))[0]
hist_df = pd.DataFrame({'Hour': range(24), 'Count': hist_values})
st.bar_chart(hist_df.set_index('Hour'))

# 5-3. í•„í„°ë§ëœ ì›ë³¸ ë°ì´í„° ë³´ê¸°
if st.checkbox('í•„í„°ë§ëœ ì›ë³¸ ë°ì´í„° ë³´ê¸°'):
    st.subheader(f"{hour_to_filter}:00ì˜ í•„í„°ë§ëœ ë°ì´í„°")
    st.dataframe(filtered_data.drop(['cluster', 'color'], errors='ignore'))
